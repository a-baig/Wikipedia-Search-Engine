{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1161c5bf",
   "metadata": {},
   "source": [
    "## **CONSTANTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40f5891d",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = \"./data/simplewiki-latest-pages-articles-multistream.xml.bz2\"\n",
    "CSV_OUTPUT = \"./data/simplewiki_articles.csv\"\n",
    "PROCESSED_TOKENS_OUTPUT = \"./data/dataset_with_processed_tokens.jsonl\"\n",
    "INVERTED_INDEX_FILE = \"./data/inverted_index.pkl\"\n",
    "INVERSE_DOCUMENT_FREQUENCY_FILE = \"./data/inverse_document_frequency.pkl\"\n",
    "SQL_DATABASE_FILENAME = './db/wikipedia_snippets.db'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c469e5",
   "metadata": {},
   "source": [
    "## **Utility Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e62ec92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pympler import asizeof\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b92c871",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\baigj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\baigj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e810e650",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEMMER = PorterStemmer()\n",
    "STOP_WORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f55d5943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_memory_consumed(obj):\n",
    "    size_bytes = asizeof.asizeof(obj)\n",
    "    size_mb = size_bytes / (1024 * 1024)\n",
    "    print(f\"{size_mb:.2f} MB\")\n",
    "    \n",
    "    return size_mb\n",
    "\n",
    "def preprocess_text(text) -> list[str]:\n",
    "    \n",
    "    # Step 1: Normalize the text to keep only alphanumeric text and single space instead of multiple spaces.\n",
    "    text = re.sub(r'[^a-z0-9\\s]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # Step 2: Tokenize the entire text\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Step 3: For each token -> filter out stopwords and tokens with only 1 character, lowercase, and stem to base form\n",
    "    processed_tokens = [\n",
    "        STEMMER.stem(token)\n",
    "        for token in tokens\n",
    "        if (token not in STOP_WORDS and len(token) > 1)\n",
    "    ]\n",
    "    \n",
    "    # Step 4: Return the processed tokens\n",
    "    return processed_tokens\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02df9535",
   "metadata": {},
   "source": [
    "## **BM25 Implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3d10a244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12061675",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Armghan\\Wikipedia Dataset\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:130: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\baigj\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 312.90it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "MODEL = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d9ea12",
   "metadata": {},
   "source": [
    "#### **Load the stored inverted index and inverse document frequency**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d913044",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(INVERTED_INDEX_FILE, \"rb\") as f:\n",
    "    inverted_index = pickle.load(f)\n",
    "\n",
    "with open(INVERSE_DOCUMENT_FREQUENCY_FILE, \"rb\") as f:\n",
    "    idf_data = pickle.load(f)\n",
    "    \n",
    "idf = idf_data['idf']\n",
    "total_doc_count = idf_data['total_documents']\n",
    "doc_lengths = idf_data[\"doc_lengths\"]\n",
    "avg_doc_length = idf_data[\"avg_doc_length\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db94fe25",
   "metadata": {},
   "source": [
    "**Function to get PageIds from Inverted Indexes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e44fc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_and_retrieve_pages_with_bm25(query, top_k=20, k1=1.5, b=0.75):\n",
    "\n",
    "    query = query.lower()\n",
    "    processed_tokens = preprocess_text(query)\n",
    "\n",
    "    scores = defaultdict(float)\n",
    "\n",
    "    for term in processed_tokens:\n",
    "        if term not in inverted_index:\n",
    "            continue\n",
    "\n",
    "        postings = inverted_index[term]     # {page_id: tf}\n",
    "        term_idf = idf.get(term, 0.0)\n",
    "\n",
    "        for page_id, tf in postings.items():\n",
    "            dl = doc_lengths.get(page_id, 0)\n",
    "\n",
    "            denom = tf + k1 * (1 - b + b * (dl / avg_doc_length))\n",
    "            bm25_tf = (tf * (k1 + 1)) / denom if denom != 0 else 0\n",
    "\n",
    "            scores[page_id] += term_idf * bm25_tf\n",
    "\n",
    "    ranked_docs = sorted(\n",
    "        scores.items(),\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True\n",
    "    )\n",
    "\n",
    "    return [page_id for page_id, _ in ranked_docs[:top_k]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b07c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_query(query):\n",
    "    \n",
    "    # Step 1: First Stage Ranking: Get the BM25 Ranked Candidate document IDs from inverted index.\n",
    "    pageIds = rank_and_retrieve_pages_with_bm25(query, top_k=20)\n",
    "    if not pageIds:\n",
    "        return []\n",
    "\n",
    "    # Step 2: Fetch Candidate Document Data from Database\n",
    "    with sqlite3.connect(SQL_DATABASE_FILENAME) as conn:\n",
    "        cursor = conn.cursor()\n",
    "        placeholders = ','.join(['?'] * len(pageIds))\n",
    "        sql = f\"SELECT PageId, Title, Snippet, URL FROM articles WHERE PageId IN ({placeholders})\"\n",
    "        cursor.execute(sql, pageIds)\n",
    "        results = cursor.fetchall()\n",
    "\n",
    "    # Step 3: Re-arrange the fetched documents in order of the BM25 ranked PageIds. Because SQLite returns data in random order\n",
    "    results_dict = {}\n",
    "    docs = []\n",
    "    \n",
    "    for page_data in results:\n",
    "        results_dict[page_data[0]] = page_data # -> {\"PageId\" : Page Data}\n",
    "    \n",
    "    for pageId in pageIds:\n",
    "        if pageId in results_dict:\n",
    "            docs.append(results_dict.get(pageId)) # Append the page data in order of the BM25 ranked pageIds\n",
    "    \n",
    "    if not docs:\n",
    "        return []\n",
    "    \n",
    "    # Step 4: Second Stage Re-Ranking: Match the semantic similarity of the title with query.\n",
    "    doc_texts = []\n",
    "    for page_data in docs:\n",
    "        doc_texts.append(f\"{page_data[1]}. {page_data[2]}\") # page_data[1] is Title and page_data[2] is snippet.\n",
    "    \n",
    "    query_vector = MODEL.encode([query])\n",
    "    doc_vectors = MODEL.encode(doc_texts)\n",
    "    \n",
    "    semantic_scores =  cosine_similarity(query_vector, doc_vectors)[0]\n",
    "    \n",
    "    # Step 5: Rerank by semantic similarity\n",
    "    reranked = sorted(\n",
    "        zip(docs, semantic_scores),\n",
    "        key=lambda doc: doc[1], # -> Rank by semantic score which will be at index 1\n",
    "        reverse=True # High score to Low score\n",
    "    )\n",
    "\n",
    "    return [doc for doc, score in reranked]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3a03de5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('39',\n",
       "  'Apple',\n",
       "  'thumb|Granny Smith green apples\\n\\nAn apple is a sweet, edible fruit that is usually red or green. The tree (Malus spp.) is grown worldwide. The fruit is low-cost, popular, and common all over the earth & taste is fruity. \\n\\nThe apple tree comes from southern Kazakhstan; Kyrgyzstan; Uzbekistan; Turkey; and northwestern part of China. Apples have been grown for thousands of years in Asia and in European continent. They were brought to North America by European World Colonial settlers. Apples have Re',\n",
       "  'https://simple.wikipedia.org/wiki/Apple'),\n",
       " ('46074',\n",
       "  'Pond-apple',\n",
       "  'A pond-apple is a type of fruit. It is not related to the apple. They usually live near or in water.\\n\\nCategory:Annona\\nCategory:Fruits',\n",
       "  'https://simple.wikipedia.org/wiki/Pond-apple'),\n",
       " ('85724',\n",
       "  \"Adam's apple (disambiguation)\",\n",
       "  'An Adam\\'s apple is a structure in the front of the throat more prominent in men than women.\\n\\nAdam\\'s apple can also mean:\\n\\nAdam\\'s Apples, a 2005 Danish movie\\nAdam\\'s Apple (album), a 1966 album by Wayne Shorter\\n\"Adam\\'s Apple\" (song), a 1975 song by Aerosmith\\nAdam\\'s Apple (2004 album), by John Wesley Harding\\n\\nRelated pages\\nForbidden fruit',\n",
       "  \"https://simple.wikipedia.org/wiki/Adam's_apple_(disambiguation)\"),\n",
       " ('85723',\n",
       "  \"Adam's apple\",\n",
       "  \"thumb|Adam's apple\\n\\nThe Adam's apple is a feature of the human neck. The medical name in English for it is the laryngeal prominence. This lump is formed by the angle of the thyroid cartilage (a type of soft bone) around the larynx (part of the throat which holds the vocal chords).\\n\\nThe Adam's apple can usually be seen better in adult men than in women, girls, or boys. The Adam's apple is only part of the thyroid cartilage around the larynx. A large Adam's apple is commonly seen as a male seconda\",\n",
       "  \"https://simple.wikipedia.org/wiki/Adam's_apple\"),\n",
       " ('38325',\n",
       "  'Juice',\n",
       "  'thumb|right|A glass of orange juice\\nJuice is a liquid that comes from plants, animals or fruit. The juice from fruit is often made into a drink. Some fruits that are often made into drinks are apple, orange, tomato, pineapple, grapefruit, guava, mango, passionfruit, watermelon, cranberry, grape, lemon and lime, but there are many others. \\n\\nIn the United Kingdom the name of a fruit or fruits followed by juice can only legally be used to describe something which is 100% fruit juice. This is becaus',\n",
       "  'https://simple.wikipedia.org/wiki/Juice'),\n",
       " ('85727',\n",
       "  'Forbidden fruit',\n",
       "  'thumb|Adam and Eve fell from the Garden of Eden. Eve still holds the forbidden fruit in her hand.\\n\\nThe words forbidden fruit stand as a metaphor (an image). The metaphor comes from the book of Genesis in the Bible. There Adam and Eve are thrown out of Paradise because they eat from the tree of knowledge.Old Testament, Genesis 1:16-17, \"And the Lord God commanded the man, saying, Of every tree of the garden thou mayest freely eat: But of the tree of the knowledge of good and evil, thou shalt not ',\n",
       "  'https://simple.wikipedia.org/wiki/Forbidden_fruit'),\n",
       " ('919758',\n",
       "  'American Mayapple',\n",
       "  \"thumb|An American Mayapple on Its Plant\\nThe American Mayapple is a herbaceous perennial plant native to the eastern part of North America. The stem can grow up to 30-40 cm tall. The plant produces two distinct growth forms. The first form, which has a single umbrella-like leaf, doesn't make any flowers or fruit. The second growth form consists of twin leaves (sometimes three), and a single white flower with six (rarely up to nine) petals, typically measuring 3-5 cm in diameter. This flower matur\",\n",
       "  'https://simple.wikipedia.org/wiki/American_Mayapple'),\n",
       " ('40926',\n",
       "  'If and only if',\n",
       "  'INPUT  OUTPUT A  B  A  B0  0  10  1  01  0  01  1  1\\n\\nIn logic and mathematics, if and only if (sometimes abbreviated as iff) is a logical operator denoting a logical biconditional (often symbolized by  or). It is often used to conjoin two statements which are logically equivalent. \\n\\nIn general, given two statement A and B, the statement \"A if and only if B\" is true precisely when both A and B are true or both A and B are false. In which case, A can be thought of as the logical substitute of B (',\n",
       "  'https://simple.wikipedia.org/wiki/If_and_only_if')]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_query(\"What is an apple fruit?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1218f265",
   "metadata": {},
   "source": [
    "## **Free Memory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33618f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "del idf\n",
    "del idf_data\n",
    "del inverted_index\n",
    "del total_doc_count\n",
    "del doc_lengths\n",
    "del avg_doc_length\n",
    "\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
